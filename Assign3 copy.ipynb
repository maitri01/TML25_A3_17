{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34163f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import numpy as np\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9fb116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b320ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f0d837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5)\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcb9b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset of length: 100000\n"
     ]
    }
   ],
   "source": [
    "import __main__\n",
    "torch.serialization.add_safe_globals([__main__.TaskDataset])\n",
    "\n",
    "dataset = torch.load(\"Train.pt\", weights_only=False)\n",
    "print(f\"Loaded dataset of length: {len(dataset)}\")\n",
    "\n",
    "# Split dataset 90/10\n",
    "dataset_size = len(dataset)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Assign transforms to base datasets inside subsets\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7533e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgLabelDataset(Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base = base_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.base[idx]\n",
    "        return sample[1], sample[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfe01941",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128  # Adjust based on your GPU memory\n",
    "\n",
    "train_loader = DataLoader(ImgLabelDataset(train_dataset), batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(ImgLabelDataset(val_dataset), batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42b96f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)  # 10 classes for your task\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels, eps, alpha, iters, device='cuda'):\n",
    "    model.eval()\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    ori_images = images.clone().detach()\n",
    "    perturbed_images = images + torch.empty_like(images).uniform_(-eps, eps)\n",
    "    perturbed_images = torch.clamp(perturbed_images, 0, 1).detach()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for _ in range(iters):\n",
    "        perturbed_images.requires_grad = True\n",
    "        outputs = model(perturbed_images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad_sign = perturbed_images.grad.sign()\n",
    "        adv_images = perturbed_images + alpha * grad_sign\n",
    "        eta = torch.clamp(adv_images - ori_images, -eps, eps)\n",
    "        perturbed_images = torch.clamp(ori_images + eta, 0, 1).detach()\n",
    "    model.train()\n",
    "    return perturbed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_clean(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8928b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_adv(model, loader, optimizer, criterion, device,\n",
    "                        eps=4/255, alpha=1/255, pgd_iters=7, mix_clean=True):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        adv_imgs = pgd_attack(model, imgs, labels, eps, alpha, pgd_iters, device)\n",
    "        optimizer.zero_grad()\n",
    "        if mix_clean:\n",
    "            out_clean = model(imgs)\n",
    "            out_adv = model(adv_imgs)\n",
    "            loss = 0.5 * (criterion(out_clean, labels) + criterion(out_adv, labels))\n",
    "        else:\n",
    "            out_adv = model(adv_imgs)\n",
    "            loss = criterion(out_adv, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, device, attack=None, eps=4/255, alpha=1/255, iters=7):\n",
    "    model.eval()\n",
    "    correct_clean = 0\n",
    "    correct_adv = 0\n",
    "    total = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        total += labels.size(0)\n",
    "        outputs = model(imgs)\n",
    "        _, pred = outputs.max(1)\n",
    "        correct_clean += pred.eq(labels).sum().item()\n",
    "        if attack is not None:\n",
    "            with torch.enable_grad():\n",
    "                adv_imgs = attack(model, imgs, labels, eps, alpha, iters, device=device)\n",
    "            outputs_adv = model(adv_imgs)\n",
    "            _, pred_adv = outputs_adv.max(1)\n",
    "            correct_adv += pred_adv.eq(labels).sum().item()\n",
    "    clean_acc = 100 * correct_clean / total\n",
    "    adv_acc = 100 * correct_adv / total if attack is not None else None\n",
    "    return clean_acc, adv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- TRAINING FLOW ----\n",
    "best_val_acc = 0\n",
    "best_model_path = \"submission_model01.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6db03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Clean training\n",
      "Train batch 0/704 loss: 2.4518\n",
      "Train batch 100/704 loss: 1.7031\n",
      "Train batch 200/704 loss: 1.5539\n",
      "Train batch 300/704 loss: 1.5417\n",
      "Train batch 400/704 loss: 1.5765\n",
      "Train batch 500/704 loss: 1.4241\n",
      "Train batch 600/704 loss: 1.5569\n",
      "Train batch 700/704 loss: 1.3850\n",
      "Clean training epoch loss: 1.5601\n",
      "Loss: 1.5601\n",
      "Validation Accuracy: 54.360%\n",
      "Saved best clean model with accuracy 54.360%\n",
      "Epoch 2/60 - Clean training\n",
      "Train batch 0/704 loss: 1.4592\n",
      "Train batch 100/704 loss: 1.5436\n",
      "Train batch 200/704 loss: 1.3399\n",
      "Train batch 300/704 loss: 1.4240\n",
      "Train batch 400/704 loss: 1.4923\n",
      "Train batch 500/704 loss: 1.4721\n",
      "Train batch 600/704 loss: 1.5403\n",
      "Train batch 700/704 loss: 1.4344\n",
      "Clean training epoch loss: 1.4640\n",
      "Loss: 1.4640\n",
      "Validation Accuracy: 54.900%\n",
      "Saved best clean model with accuracy 54.900%\n",
      "Epoch 3/60 - Clean training\n",
      "Train batch 0/704 loss: 1.3535\n",
      "Train batch 100/704 loss: 1.3910\n",
      "Train batch 200/704 loss: 1.3294\n",
      "Train batch 300/704 loss: 1.4055\n",
      "Train batch 400/704 loss: 1.4910\n",
      "Train batch 500/704 loss: 1.4079\n",
      "Train batch 600/704 loss: 1.3885\n",
      "Train batch 700/704 loss: 1.3089\n",
      "Clean training epoch loss: 1.4239\n",
      "Loss: 1.4239\n",
      "Validation Accuracy: 54.870%\n",
      "Epoch 4/60 - Clean training\n",
      "Train batch 0/704 loss: 1.4432\n",
      "Train batch 100/704 loss: 1.3885\n",
      "Train batch 200/704 loss: 1.5122\n",
      "Train batch 300/704 loss: 1.5003\n",
      "Train batch 400/704 loss: 1.4172\n",
      "Train batch 500/704 loss: 1.3319\n",
      "Train batch 600/704 loss: 1.3174\n",
      "Train batch 700/704 loss: 1.3589\n",
      "Clean training epoch loss: 1.3929\n",
      "Loss: 1.3929\n",
      "Validation Accuracy: 56.490%\n",
      "Saved best clean model with accuracy 56.490%\n",
      "Epoch 5/60 - Clean training\n",
      "Train batch 0/704 loss: 1.4352\n",
      "Train batch 100/704 loss: 1.2422\n",
      "Train batch 200/704 loss: 1.2668\n",
      "Train batch 300/704 loss: 1.4215\n",
      "Train batch 400/704 loss: 1.4091\n",
      "Train batch 500/704 loss: 1.3815\n",
      "Train batch 600/704 loss: 1.2615\n",
      "Train batch 700/704 loss: 1.4528\n",
      "Clean training epoch loss: 1.3702\n",
      "Loss: 1.3702\n",
      "Validation Accuracy: 56.760%\n",
      "Saved best clean model with accuracy 56.760%\n",
      "Epoch 6/60 - Clean training\n",
      "Train batch 0/704 loss: 1.2487\n",
      "Train batch 100/704 loss: 1.2895\n",
      "Train batch 200/704 loss: 1.3322\n",
      "Train batch 300/704 loss: 1.5417\n",
      "Train batch 400/704 loss: 1.4188\n",
      "Train batch 500/704 loss: 1.4148\n",
      "Train batch 600/704 loss: 1.2117\n",
      "Train batch 700/704 loss: 1.3454\n",
      "Clean training epoch loss: 1.3399\n",
      "Loss: 1.3399\n",
      "Validation Accuracy: 54.480%\n",
      "Epoch 7/60 - Clean training\n",
      "Train batch 0/704 loss: 1.2881\n",
      "Train batch 100/704 loss: 1.2365\n",
      "Train batch 200/704 loss: 1.2549\n",
      "Train batch 300/704 loss: 1.3399\n",
      "Train batch 400/704 loss: 1.3296\n",
      "Train batch 500/704 loss: 1.2431\n",
      "Train batch 600/704 loss: 1.3265\n",
      "Train batch 700/704 loss: 1.2977\n",
      "Clean training epoch loss: 1.3125\n",
      "Loss: 1.3125\n",
      "Validation Accuracy: 56.260%\n",
      "Epoch 8/60 - Clean training\n",
      "Train batch 0/704 loss: 1.3440\n",
      "Train batch 100/704 loss: 1.3725\n",
      "Train batch 200/704 loss: 1.1497\n",
      "Train batch 300/704 loss: 1.4275\n",
      "Train batch 400/704 loss: 1.3368\n",
      "Train batch 500/704 loss: 1.2418\n",
      "Train batch 600/704 loss: 1.3170\n",
      "Train batch 700/704 loss: 1.4921\n",
      "Clean training epoch loss: 1.2879\n",
      "Loss: 1.2879\n",
      "Validation Accuracy: 57.130%\n",
      "Saved best clean model with accuracy 57.130%\n",
      "Epoch 9/60 - Clean training\n",
      "Train batch 0/704 loss: 1.3076\n",
      "Train batch 100/704 loss: 1.2598\n",
      "Train batch 200/704 loss: 1.1167\n",
      "Train batch 300/704 loss: 1.3090\n",
      "Train batch 400/704 loss: 1.1631\n",
      "Train batch 500/704 loss: 1.3289\n",
      "Train batch 600/704 loss: 1.2632\n",
      "Train batch 700/704 loss: 1.1620\n",
      "Clean training epoch loss: 1.2636\n",
      "Loss: 1.2636\n",
      "Validation Accuracy: 59.980%\n",
      "Saved best clean model with accuracy 59.980%\n",
      "Epoch 10/60 - Clean training\n",
      "Train batch 0/704 loss: 1.3067\n",
      "Train batch 100/704 loss: 1.2395\n",
      "Train batch 200/704 loss: 1.2101\n",
      "Train batch 300/704 loss: 1.2049\n",
      "Train batch 400/704 loss: 1.3114\n",
      "Train batch 500/704 loss: 1.2145\n",
      "Train batch 600/704 loss: 1.1262\n",
      "Train batch 700/704 loss: 1.3543\n",
      "Clean training epoch loss: 1.2388\n",
      "Loss: 1.2388\n",
      "Validation Accuracy: 60.020%\n",
      "Saved best clean model with accuracy 60.020%\n",
      "Epoch 11/60 - Clean training\n",
      "Train batch 0/704 loss: 1.2486\n",
      "Train batch 100/704 loss: 1.1011\n",
      "Train batch 200/704 loss: 1.1823\n",
      "Train batch 300/704 loss: 1.2997\n",
      "Train batch 400/704 loss: 1.2503\n",
      "Train batch 500/704 loss: 1.1273\n",
      "Train batch 600/704 loss: 1.2347\n",
      "Train batch 700/704 loss: 1.2705\n",
      "Clean training epoch loss: 1.2066\n",
      "Loss: 1.2066\n",
      "Validation Accuracy: 60.460%\n",
      "Saved best clean model with accuracy 60.460%\n",
      "Epoch 12/60 - Clean training\n",
      "Train batch 0/704 loss: 1.1219\n",
      "Train batch 100/704 loss: 1.1100\n",
      "Train batch 200/704 loss: 1.2266\n",
      "Train batch 300/704 loss: 1.1551\n",
      "Train batch 400/704 loss: 1.1033\n",
      "Train batch 500/704 loss: 1.0684\n",
      "Train batch 600/704 loss: 1.3912\n",
      "Train batch 700/704 loss: 1.2259\n",
      "Clean training epoch loss: 1.1739\n",
      "Loss: 1.1739\n",
      "Validation Accuracy: 50.320%\n",
      "Epoch 13/60 - Clean training\n",
      "Train batch 0/704 loss: 1.1110\n",
      "Train batch 100/704 loss: 1.2155\n",
      "Train batch 200/704 loss: 1.0753\n",
      "Train batch 300/704 loss: 1.1732\n",
      "Train batch 400/704 loss: 1.1643\n",
      "Train batch 500/704 loss: 1.0879\n",
      "Train batch 600/704 loss: 1.1788\n",
      "Train batch 700/704 loss: 1.1751\n",
      "Clean training epoch loss: 1.1337\n",
      "Loss: 1.1337\n",
      "Validation Accuracy: 59.010%\n",
      "Epoch 14/60 - Clean training\n",
      "Train batch 0/704 loss: 0.9981\n",
      "Train batch 100/704 loss: 1.0857\n",
      "Train batch 200/704 loss: 1.0354\n",
      "Train batch 300/704 loss: 1.1138\n",
      "Train batch 400/704 loss: 1.0431\n",
      "Train batch 500/704 loss: 1.0709\n",
      "Train batch 600/704 loss: 1.2026\n",
      "Train batch 700/704 loss: 1.0367\n",
      "Clean training epoch loss: 1.0841\n",
      "Loss: 1.0841\n",
      "Validation Accuracy: 60.090%\n",
      "Epoch 15/60 - Clean training\n",
      "Train batch 0/704 loss: 1.0621\n",
      "Train batch 100/704 loss: 0.8769\n",
      "Train batch 200/704 loss: 0.9215\n",
      "Train batch 300/704 loss: 0.9645\n",
      "Train batch 400/704 loss: 1.0925\n",
      "Train batch 500/704 loss: 1.0759\n",
      "Train batch 600/704 loss: 1.0248\n",
      "Train batch 700/704 loss: 1.0315\n",
      "Clean training epoch loss: 1.0309\n",
      "Loss: 1.0309\n",
      "Validation Accuracy: 60.400%\n",
      "Epoch 16/60 - Clean training\n",
      "Train batch 0/704 loss: 0.9062\n",
      "Train batch 100/704 loss: 0.8883\n",
      "Train batch 200/704 loss: 1.0651\n",
      "Train batch 300/704 loss: 0.8772\n",
      "Train batch 400/704 loss: 0.9962\n",
      "Train batch 500/704 loss: 1.0354\n",
      "Train batch 600/704 loss: 0.8846\n",
      "Train batch 700/704 loss: 0.8613\n",
      "Clean training epoch loss: 0.9719\n",
      "Loss: 0.9719\n",
      "Validation Accuracy: 61.000%\n",
      "Saved best clean model with accuracy 61.000%\n",
      "Epoch 17/60 - Clean training\n",
      "Train batch 0/704 loss: 0.8129\n",
      "Train batch 100/704 loss: 0.8187\n",
      "Train batch 200/704 loss: 0.8443\n",
      "Train batch 300/704 loss: 0.9389\n",
      "Train batch 400/704 loss: 0.9484\n",
      "Train batch 500/704 loss: 0.9298\n",
      "Train batch 600/704 loss: 0.9239\n",
      "Train batch 700/704 loss: 0.8610\n",
      "Clean training epoch loss: 0.9099\n",
      "Loss: 0.9099\n",
      "Validation Accuracy: 60.030%\n",
      "Epoch 18/60 - Clean training\n",
      "Train batch 0/704 loss: 0.7826\n",
      "Train batch 100/704 loss: 0.8472\n",
      "Train batch 200/704 loss: 0.9788\n",
      "Train batch 300/704 loss: 0.9275\n",
      "Train batch 400/704 loss: 0.8194\n",
      "Train batch 500/704 loss: 0.9567\n",
      "Train batch 600/704 loss: 0.9741\n",
      "Train batch 700/704 loss: 0.9056\n",
      "Clean training epoch loss: 0.8509\n",
      "Loss: 0.8509\n",
      "Validation Accuracy: 59.750%\n",
      "Epoch 19/60 - Clean training\n",
      "Train batch 0/704 loss: 0.7664\n",
      "Train batch 100/704 loss: 0.7195\n",
      "Train batch 200/704 loss: 0.6871\n",
      "Train batch 300/704 loss: 0.7248\n",
      "Train batch 400/704 loss: 0.8184\n",
      "Train batch 500/704 loss: 0.8497\n",
      "Train batch 600/704 loss: 0.8041\n",
      "Train batch 700/704 loss: 0.9533\n",
      "Clean training epoch loss: 0.7932\n",
      "Loss: 0.7932\n",
      "Validation Accuracy: 59.650%\n",
      "Epoch 20/60 - Clean training\n",
      "Train batch 0/704 loss: 0.6803\n",
      "Train batch 100/704 loss: 0.6753\n",
      "Train batch 200/704 loss: 0.7106\n",
      "Train batch 300/704 loss: 0.7118\n",
      "Train batch 400/704 loss: 0.7604\n",
      "Train batch 500/704 loss: 0.7861\n",
      "Train batch 600/704 loss: 0.7276\n",
      "Train batch 700/704 loss: 0.8157\n",
      "Clean training epoch loss: 0.7475\n",
      "Loss: 0.7475\n",
      "Validation Accuracy: 59.050%\n",
      "Epoch 21/60 - Clean training\n",
      "Train batch 0/704 loss: 0.6603\n",
      "Train batch 100/704 loss: 0.7044\n",
      "Train batch 200/704 loss: 0.6772\n",
      "Train batch 300/704 loss: 0.7263\n",
      "Train batch 400/704 loss: 0.7747\n",
      "Train batch 500/704 loss: 0.7365\n",
      "Train batch 600/704 loss: 0.6639\n",
      "Train batch 700/704 loss: 0.7308\n",
      "Clean training epoch loss: 0.7061\n",
      "Loss: 0.7061\n",
      "Validation Accuracy: 60.030%\n",
      "Epoch 22/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5771\n",
      "Train batch 100/704 loss: 0.6865\n",
      "Train batch 200/704 loss: 0.5951\n",
      "Train batch 300/704 loss: 0.6978\n",
      "Train batch 400/704 loss: 0.6300\n",
      "Train batch 500/704 loss: 0.6505\n",
      "Train batch 600/704 loss: 0.6613\n",
      "Train batch 700/704 loss: 0.7850\n",
      "Clean training epoch loss: 0.6718\n",
      "Loss: 0.6718\n",
      "Validation Accuracy: 58.780%\n",
      "Epoch 23/60 - Clean training\n",
      "Train batch 0/704 loss: 0.6890\n",
      "Train batch 100/704 loss: 0.5600\n",
      "Train batch 200/704 loss: 0.6319\n",
      "Train batch 300/704 loss: 0.7287\n",
      "Train batch 400/704 loss: 0.6641\n",
      "Train batch 500/704 loss: 0.6414\n",
      "Train batch 600/704 loss: 0.6752\n",
      "Train batch 700/704 loss: 0.6251\n",
      "Clean training epoch loss: 0.6386\n",
      "Loss: 0.6386\n",
      "Validation Accuracy: 58.750%\n",
      "Epoch 24/60 - Clean training\n",
      "Train batch 0/704 loss: 0.6426\n",
      "Train batch 100/704 loss: 0.5998\n",
      "Train batch 200/704 loss: 0.6132\n",
      "Train batch 300/704 loss: 0.5794\n",
      "Train batch 400/704 loss: 0.6240\n",
      "Train batch 500/704 loss: 0.5952\n",
      "Train batch 600/704 loss: 0.6902\n",
      "Train batch 700/704 loss: 0.6809\n",
      "Clean training epoch loss: 0.6188\n",
      "Loss: 0.6188\n",
      "Validation Accuracy: 58.670%\n",
      "Epoch 25/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5642\n",
      "Train batch 100/704 loss: 0.5577\n",
      "Train batch 200/704 loss: 0.5797\n",
      "Train batch 300/704 loss: 0.5770\n",
      "Train batch 400/704 loss: 0.5744\n",
      "Train batch 500/704 loss: 0.6167\n",
      "Train batch 600/704 loss: 0.5658\n",
      "Train batch 700/704 loss: 0.6893\n",
      "Clean training epoch loss: 0.5948\n",
      "Loss: 0.5948\n",
      "Validation Accuracy: 58.670%\n",
      "Epoch 26/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5536\n",
      "Train batch 100/704 loss: 0.6697\n",
      "Train batch 200/704 loss: 0.5392\n",
      "Train batch 300/704 loss: 0.5402\n",
      "Train batch 400/704 loss: 0.5666\n",
      "Train batch 500/704 loss: 0.5795\n",
      "Train batch 600/704 loss: 0.6019\n",
      "Train batch 700/704 loss: 0.5459\n",
      "Clean training epoch loss: 0.5788\n",
      "Loss: 0.5788\n",
      "Validation Accuracy: 58.600%\n",
      "Epoch 27/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5786\n",
      "Train batch 100/704 loss: 0.6174\n",
      "Train batch 200/704 loss: 0.5658\n",
      "Train batch 300/704 loss: 0.5515\n",
      "Train batch 400/704 loss: 0.5519\n",
      "Train batch 500/704 loss: 0.5496\n",
      "Train batch 600/704 loss: 0.5820\n",
      "Train batch 700/704 loss: 0.5414\n",
      "Clean training epoch loss: 0.5629\n",
      "Loss: 0.5629\n",
      "Validation Accuracy: 58.750%\n",
      "Epoch 28/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5139\n",
      "Train batch 100/704 loss: 0.5313\n",
      "Train batch 200/704 loss: 0.5191\n",
      "Train batch 300/704 loss: 0.5455\n",
      "Train batch 400/704 loss: 0.5291\n",
      "Train batch 500/704 loss: 0.5647\n",
      "Train batch 600/704 loss: 0.5740\n",
      "Train batch 700/704 loss: 0.5428\n",
      "Clean training epoch loss: 0.5477\n",
      "Loss: 0.5477\n",
      "Validation Accuracy: 59.180%\n",
      "Epoch 29/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5542\n",
      "Train batch 100/704 loss: 0.5136\n",
      "Train batch 200/704 loss: 0.5266\n",
      "Train batch 300/704 loss: 0.5181\n",
      "Train batch 400/704 loss: 0.5218\n",
      "Train batch 500/704 loss: 0.5121\n",
      "Train batch 600/704 loss: 0.5361\n",
      "Train batch 700/704 loss: 0.5193\n",
      "Clean training epoch loss: 0.5398\n",
      "Loss: 0.5398\n",
      "Validation Accuracy: 59.320%\n",
      "Epoch 30/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5257\n",
      "Train batch 100/704 loss: 0.5446\n",
      "Train batch 200/704 loss: 0.5100\n",
      "Train batch 300/704 loss: 0.5369\n",
      "Train batch 400/704 loss: 0.5498\n",
      "Train batch 500/704 loss: 0.5213\n",
      "Train batch 600/704 loss: 0.5063\n",
      "Train batch 700/704 loss: 0.5224\n",
      "Clean training epoch loss: 0.5341\n",
      "Loss: 0.5341\n",
      "Validation Accuracy: 58.690%\n",
      "Epoch 31/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5038\n",
      "Train batch 100/704 loss: 0.5479\n",
      "Train batch 200/704 loss: 0.5279\n",
      "Train batch 300/704 loss: 0.5129\n",
      "Train batch 400/704 loss: 0.5734\n",
      "Train batch 500/704 loss: 0.5275\n",
      "Train batch 600/704 loss: 0.5230\n",
      "Train batch 700/704 loss: 0.5776\n",
      "Clean training epoch loss: 0.5254\n",
      "Loss: 0.5254\n",
      "Validation Accuracy: 59.350%\n",
      "Epoch 32/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5113\n",
      "Train batch 100/704 loss: 0.5136\n",
      "Train batch 200/704 loss: 0.5042\n",
      "Train batch 300/704 loss: 0.5060\n",
      "Train batch 400/704 loss: 0.5226\n",
      "Train batch 500/704 loss: 0.5526\n",
      "Train batch 600/704 loss: 0.5103\n",
      "Train batch 700/704 loss: 0.5255\n",
      "Clean training epoch loss: 0.5185\n",
      "Loss: 0.5185\n",
      "Validation Accuracy: 59.380%\n",
      "Epoch 33/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5097\n",
      "Train batch 100/704 loss: 0.5327\n",
      "Train batch 200/704 loss: 0.5135\n",
      "Train batch 300/704 loss: 0.5138\n",
      "Train batch 400/704 loss: 0.5105\n",
      "Train batch 500/704 loss: 0.5263\n",
      "Train batch 600/704 loss: 0.5106\n",
      "Train batch 700/704 loss: 0.5035\n",
      "Clean training epoch loss: 0.5150\n",
      "Loss: 0.5150\n",
      "Validation Accuracy: 59.640%\n",
      "Epoch 34/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5018\n",
      "Train batch 100/704 loss: 0.5027\n",
      "Train batch 200/704 loss: 0.5047\n",
      "Train batch 300/704 loss: 0.5029\n",
      "Train batch 400/704 loss: 0.5376\n",
      "Train batch 500/704 loss: 0.5496\n",
      "Train batch 600/704 loss: 0.5035\n",
      "Train batch 700/704 loss: 0.5045\n",
      "Clean training epoch loss: 0.5117\n",
      "Loss: 0.5117\n",
      "Validation Accuracy: 59.550%\n",
      "Epoch 35/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5042\n",
      "Train batch 100/704 loss: 0.5045\n",
      "Train batch 200/704 loss: 0.5022\n",
      "Train batch 300/704 loss: 0.5140\n",
      "Train batch 400/704 loss: 0.5021\n",
      "Train batch 500/704 loss: 0.5064\n",
      "Train batch 600/704 loss: 0.5075\n",
      "Train batch 700/704 loss: 0.5024\n",
      "Clean training epoch loss: 0.5098\n",
      "Loss: 0.5098\n",
      "Validation Accuracy: 59.820%\n",
      "Epoch 36/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5046\n",
      "Train batch 100/704 loss: 0.5057\n",
      "Train batch 200/704 loss: 0.5023\n",
      "Train batch 300/704 loss: 0.5164\n",
      "Train batch 400/704 loss: 0.5032\n",
      "Train batch 500/704 loss: 0.5015\n",
      "Train batch 600/704 loss: 0.5027\n",
      "Train batch 700/704 loss: 0.5057\n",
      "Clean training epoch loss: 0.5086\n",
      "Loss: 0.5086\n",
      "Validation Accuracy: 59.660%\n",
      "Epoch 37/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5017\n",
      "Train batch 100/704 loss: 0.5018\n",
      "Train batch 200/704 loss: 0.5322\n",
      "Train batch 300/704 loss: 0.5018\n",
      "Train batch 400/704 loss: 0.5314\n",
      "Train batch 500/704 loss: 0.5048\n",
      "Train batch 600/704 loss: 0.5022\n",
      "Train batch 700/704 loss: 0.5015\n",
      "Clean training epoch loss: 0.5077\n",
      "Loss: 0.5077\n",
      "Validation Accuracy: 59.630%\n",
      "Epoch 38/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5019\n",
      "Train batch 100/704 loss: 0.5015\n",
      "Train batch 200/704 loss: 0.5045\n",
      "Train batch 300/704 loss: 0.5017\n",
      "Train batch 400/704 loss: 0.5025\n",
      "Train batch 500/704 loss: 0.5021\n",
      "Train batch 600/704 loss: 0.5020\n",
      "Train batch 700/704 loss: 0.5103\n",
      "Clean training epoch loss: 0.5070\n",
      "Loss: 0.5070\n",
      "Validation Accuracy: 59.820%\n",
      "Epoch 39/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5018\n",
      "Train batch 100/704 loss: 0.5316\n",
      "Train batch 200/704 loss: 0.5063\n",
      "Train batch 300/704 loss: 0.5027\n",
      "Train batch 400/704 loss: 0.5225\n",
      "Train batch 500/704 loss: 0.5105\n",
      "Train batch 600/704 loss: 0.5042\n",
      "Train batch 700/704 loss: 0.5019\n",
      "Clean training epoch loss: 0.5076\n",
      "Loss: 0.5076\n",
      "Validation Accuracy: 60.210%\n",
      "Epoch 40/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5020\n",
      "Train batch 100/704 loss: 0.5024\n",
      "Train batch 200/704 loss: 0.5029\n",
      "Train batch 300/704 loss: 0.5037\n",
      "Train batch 400/704 loss: 0.5017\n",
      "Train batch 500/704 loss: 0.5030\n",
      "Train batch 600/704 loss: 0.5023\n",
      "Train batch 700/704 loss: 0.5014\n",
      "Clean training epoch loss: 0.5064\n",
      "Loss: 0.5064\n",
      "Validation Accuracy: 60.200%\n",
      "Epoch 41/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5019\n",
      "Train batch 100/704 loss: 0.5022\n",
      "Train batch 200/704 loss: 0.5024\n",
      "Train batch 300/704 loss: 0.5062\n",
      "Train batch 400/704 loss: 0.5089\n",
      "Train batch 500/704 loss: 0.5017\n",
      "Train batch 600/704 loss: 0.5019\n",
      "Train batch 700/704 loss: 0.5014\n",
      "Clean training epoch loss: 0.5060\n",
      "Loss: 0.5060\n",
      "Validation Accuracy: 59.870%\n",
      "Epoch 42/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5023\n",
      "Train batch 100/704 loss: 0.5024\n",
      "Train batch 200/704 loss: 0.5035\n",
      "Train batch 300/704 loss: 0.5016\n",
      "Train batch 400/704 loss: 0.5030\n",
      "Train batch 500/704 loss: 0.5025\n",
      "Train batch 600/704 loss: 0.5146\n",
      "Train batch 700/704 loss: 0.5022\n",
      "Clean training epoch loss: 0.5062\n",
      "Loss: 0.5062\n",
      "Validation Accuracy: 60.010%\n",
      "Epoch 43/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5021\n",
      "Train batch 100/704 loss: 0.5022\n",
      "Train batch 200/704 loss: 0.5013\n",
      "Train batch 300/704 loss: 0.5017\n",
      "Train batch 400/704 loss: 0.5087\n",
      "Train batch 500/704 loss: 0.5016\n",
      "Train batch 600/704 loss: 0.5024\n",
      "Train batch 700/704 loss: 0.5011\n",
      "Clean training epoch loss: 0.5059\n",
      "Loss: 0.5059\n",
      "Validation Accuracy: 59.880%\n",
      "Epoch 44/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5018\n",
      "Train batch 100/704 loss: 0.5015\n",
      "Train batch 200/704 loss: 0.5026\n",
      "Train batch 300/704 loss: 0.5015\n",
      "Train batch 400/704 loss: 0.5012\n",
      "Train batch 500/704 loss: 0.5301\n",
      "Train batch 600/704 loss: 0.5026\n",
      "Train batch 700/704 loss: 0.5017\n",
      "Clean training epoch loss: 0.5060\n",
      "Loss: 0.5060\n",
      "Validation Accuracy: 59.880%\n",
      "Epoch 45/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5033\n",
      "Train batch 100/704 loss: 0.5017\n",
      "Train batch 200/704 loss: 0.5154\n",
      "Train batch 300/704 loss: 0.5025\n",
      "Train batch 400/704 loss: 0.5016\n",
      "Train batch 500/704 loss: 0.5012\n",
      "Train batch 600/704 loss: 0.5043\n",
      "Train batch 700/704 loss: 0.5018\n",
      "Clean training epoch loss: 0.5070\n",
      "Loss: 0.5070\n",
      "Validation Accuracy: 59.380%\n",
      "Epoch 46/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5016\n",
      "Train batch 100/704 loss: 0.5023\n",
      "Train batch 200/704 loss: 0.5024\n",
      "Train batch 300/704 loss: 0.5020\n",
      "Train batch 400/704 loss: 0.5021\n",
      "Train batch 500/704 loss: 0.5187\n",
      "Train batch 600/704 loss: 0.5018\n",
      "Train batch 700/704 loss: 0.5025\n",
      "Clean training epoch loss: 0.5075\n",
      "Loss: 0.5075\n",
      "Validation Accuracy: 59.540%\n",
      "Epoch 47/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5022\n",
      "Train batch 100/704 loss: 0.5027\n",
      "Train batch 200/704 loss: 0.5274\n",
      "Train batch 300/704 loss: 0.5017\n",
      "Train batch 400/704 loss: 0.5042\n",
      "Train batch 500/704 loss: 0.5024\n",
      "Train batch 600/704 loss: 0.5065\n",
      "Train batch 700/704 loss: 0.5014\n",
      "Clean training epoch loss: 0.5091\n",
      "Loss: 0.5091\n",
      "Validation Accuracy: 59.040%\n",
      "Epoch 48/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5041\n",
      "Train batch 100/704 loss: 0.5029\n",
      "Train batch 200/704 loss: 0.5026\n",
      "Train batch 300/704 loss: 0.5280\n",
      "Train batch 400/704 loss: 0.5069\n",
      "Train batch 500/704 loss: 0.5048\n",
      "Train batch 600/704 loss: 0.5318\n",
      "Train batch 700/704 loss: 0.5255\n",
      "Clean training epoch loss: 0.5120\n",
      "Loss: 0.5120\n",
      "Validation Accuracy: 59.770%\n",
      "Epoch 49/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5030\n",
      "Train batch 100/704 loss: 0.5040\n",
      "Train batch 200/704 loss: 0.5032\n",
      "Train batch 300/704 loss: 0.5032\n",
      "Train batch 400/704 loss: 0.5055\n",
      "Train batch 500/704 loss: 0.5055\n",
      "Train batch 600/704 loss: 0.5362\n",
      "Train batch 700/704 loss: 0.5069\n",
      "Clean training epoch loss: 0.5147\n",
      "Loss: 0.5147\n",
      "Validation Accuracy: 59.560%\n",
      "Epoch 50/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5225\n",
      "Train batch 100/704 loss: 0.5204\n",
      "Train batch 200/704 loss: 0.5310\n",
      "Train batch 300/704 loss: 0.5420\n",
      "Train batch 400/704 loss: 0.5344\n",
      "Train batch 500/704 loss: 0.5293\n",
      "Train batch 600/704 loss: 0.5306\n",
      "Train batch 700/704 loss: 0.5368\n",
      "Clean training epoch loss: 0.5195\n",
      "Loss: 0.5195\n",
      "Validation Accuracy: 59.100%\n",
      "Epoch 51/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5348\n",
      "Train batch 100/704 loss: 0.5162\n",
      "Train batch 200/704 loss: 0.5260\n",
      "Train batch 300/704 loss: 0.5084\n",
      "Train batch 400/704 loss: 0.5210\n",
      "Train batch 500/704 loss: 0.5081\n",
      "Train batch 600/704 loss: 0.5122\n",
      "Train batch 700/704 loss: 0.5425\n",
      "Clean training epoch loss: 0.5287\n",
      "Loss: 0.5287\n",
      "Validation Accuracy: 58.850%\n",
      "Epoch 52/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5181\n",
      "Train batch 100/704 loss: 0.5044\n",
      "Train batch 200/704 loss: 0.5393\n",
      "Train batch 300/704 loss: 0.5066\n",
      "Train batch 400/704 loss: 0.5208\n",
      "Train batch 500/704 loss: 0.5565\n",
      "Train batch 600/704 loss: 0.5584\n",
      "Train batch 700/704 loss: 0.5453\n",
      "Clean training epoch loss: 0.5348\n",
      "Loss: 0.5348\n",
      "Validation Accuracy: 58.710%\n",
      "Epoch 53/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5165\n",
      "Train batch 100/704 loss: 0.5554\n",
      "Train batch 200/704 loss: 0.5591\n",
      "Train batch 300/704 loss: 0.5168\n",
      "Train batch 400/704 loss: 0.5416\n",
      "Train batch 500/704 loss: 0.5452\n",
      "Train batch 600/704 loss: 0.5160\n",
      "Train batch 700/704 loss: 0.5300\n",
      "Clean training epoch loss: 0.5460\n",
      "Loss: 0.5460\n",
      "Validation Accuracy: 59.120%\n",
      "Epoch 54/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5656\n",
      "Train batch 100/704 loss: 0.5622\n",
      "Train batch 200/704 loss: 0.5166\n",
      "Train batch 300/704 loss: 0.5390\n",
      "Train batch 400/704 loss: 0.5607\n",
      "Train batch 500/704 loss: 0.5888\n",
      "Train batch 600/704 loss: 0.5524\n",
      "Train batch 700/704 loss: 0.5395\n",
      "Clean training epoch loss: 0.5526\n",
      "Loss: 0.5526\n",
      "Validation Accuracy: 58.930%\n",
      "Epoch 55/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5745\n",
      "Train batch 100/704 loss: 0.5252\n",
      "Train batch 200/704 loss: 0.5324\n",
      "Train batch 300/704 loss: 0.5606\n",
      "Train batch 400/704 loss: 0.5427\n",
      "Train batch 500/704 loss: 0.5834\n",
      "Train batch 600/704 loss: 0.5601\n",
      "Train batch 700/704 loss: 0.5497\n",
      "Clean training epoch loss: 0.5587\n",
      "Loss: 0.5587\n",
      "Validation Accuracy: 58.060%\n",
      "Epoch 56/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5316\n",
      "Train batch 100/704 loss: 0.5779\n",
      "Train batch 200/704 loss: 0.5651\n",
      "Train batch 300/704 loss: 0.6241\n",
      "Train batch 400/704 loss: 0.5999\n",
      "Train batch 500/704 loss: 0.6039\n",
      "Train batch 600/704 loss: 0.5942\n",
      "Train batch 700/704 loss: 0.5773\n",
      "Clean training epoch loss: 0.5743\n",
      "Loss: 0.5743\n",
      "Validation Accuracy: 57.930%\n",
      "Epoch 57/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5314\n",
      "Train batch 100/704 loss: 0.5912\n",
      "Train batch 200/704 loss: 0.5381\n",
      "Train batch 300/704 loss: 0.6208\n",
      "Train batch 400/704 loss: 0.5956\n",
      "Train batch 500/704 loss: 0.5803\n",
      "Train batch 600/704 loss: 0.5626\n",
      "Train batch 700/704 loss: 0.5831\n",
      "Clean training epoch loss: 0.5871\n",
      "Loss: 0.5871\n",
      "Validation Accuracy: 57.810%\n",
      "Epoch 58/60 - Clean training\n",
      "Train batch 0/704 loss: 0.6399\n",
      "Train batch 100/704 loss: 0.5976\n",
      "Train batch 200/704 loss: 0.6048\n",
      "Train batch 300/704 loss: 0.6637\n",
      "Train batch 400/704 loss: 0.5952\n",
      "Train batch 500/704 loss: 0.5694\n",
      "Train batch 600/704 loss: 0.6097\n",
      "Train batch 700/704 loss: 0.6063\n",
      "Clean training epoch loss: 0.5959\n",
      "Loss: 0.5959\n",
      "Validation Accuracy: 58.360%\n",
      "Epoch 59/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5251\n",
      "Train batch 100/704 loss: 0.5705\n",
      "Train batch 200/704 loss: 0.5897\n",
      "Train batch 300/704 loss: 0.6127\n",
      "Train batch 400/704 loss: 0.6299\n",
      "Train batch 500/704 loss: 0.6150\n",
      "Train batch 600/704 loss: 0.5915\n",
      "Train batch 700/704 loss: 0.6108\n",
      "Clean training epoch loss: 0.6035\n",
      "Loss: 0.6035\n",
      "Validation Accuracy: 57.390%\n",
      "Epoch 60/60 - Clean training\n",
      "Train batch 0/704 loss: 0.5562\n",
      "Train batch 100/704 loss: 0.6161\n",
      "Train batch 200/704 loss: 0.6287\n",
      "Train batch 300/704 loss: 0.6297\n",
      "Train batch 400/704 loss: 0.6052\n",
      "Train batch 500/704 loss: 0.6661\n",
      "Train batch 600/704 loss: 0.6214\n",
      "Train batch 700/704 loss: 0.5988\n",
      "Clean training epoch loss: 0.6173\n",
      "Loss: 0.6173\n",
      "Validation Accuracy: 57.140%\n"
     ]
    }
   ],
   "source": [
    "# Phase 1: Clean training (e.g., 40 epochs)\n",
    "for epoch in range(40):\n",
    "    print(f\"Epoch {epoch+1}/40 - Clean training\")\n",
    "    loss = train_one_epoch_clean(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Loss: {loss:.4f}\")\n",
    "    val_acc, _ = validate(model, val_loader, device)\n",
    "    print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best clean model with accuracy {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c66ba668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best clean model before adversarial fine-tuning\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Lower LR for fine-tuning\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a38e19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7598\n",
      "Adv Train Loss: 1.7598\n",
      "Validation Clean Accuracy: 57.83%\n",
      "Validation Adversarial Accuracy: 68.58%\n",
      "Saved best adversarial fine-tuned model at epoch 1 with adv accuracy 68.58%\n",
      "Epoch 2/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7913\n",
      "Adv Train Loss: 1.7913\n",
      "Validation Clean Accuracy: 57.78%\n",
      "Validation Adversarial Accuracy: 69.08%\n",
      "Saved best adversarial fine-tuned model at epoch 2 with adv accuracy 69.08%\n",
      "Epoch 3/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7523\n",
      "Adv Train Loss: 1.7523\n",
      "Validation Clean Accuracy: 57.82%\n",
      "Validation Adversarial Accuracy: 68.86%\n",
      "Epoch 4/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7696\n",
      "Adv Train Loss: 1.7696\n",
      "Validation Clean Accuracy: 57.47%\n",
      "Validation Adversarial Accuracy: 68.71%\n",
      "Epoch 5/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7191\n",
      "Adv Train Loss: 1.7191\n",
      "Validation Clean Accuracy: 57.38%\n",
      "Validation Adversarial Accuracy: 68.29%\n",
      "Epoch 6/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7337\n",
      "Adv Train Loss: 1.7337\n",
      "Validation Clean Accuracy: 57.60%\n",
      "Validation Adversarial Accuracy: 68.80%\n",
      "Epoch 7/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7078\n",
      "Adv Train Loss: 1.7078\n",
      "Validation Clean Accuracy: 57.42%\n",
      "Validation Adversarial Accuracy: 68.63%\n",
      "Epoch 8/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.6978\n",
      "Adv Train Loss: 1.6978\n",
      "Validation Clean Accuracy: 57.65%\n",
      "Validation Adversarial Accuracy: 67.70%\n",
      "Epoch 9/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7118\n",
      "Adv Train Loss: 1.7118\n",
      "Validation Clean Accuracy: 57.67%\n",
      "Validation Adversarial Accuracy: 67.50%\n",
      "Epoch 10/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.6809\n",
      "Adv Train Loss: 1.6809\n",
      "Validation Clean Accuracy: 57.90%\n",
      "Validation Adversarial Accuracy: 68.00%\n",
      "Epoch 11/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.6839\n",
      "Adv Train Loss: 1.6839\n",
      "Validation Clean Accuracy: 57.46%\n",
      "Validation Adversarial Accuracy: 67.30%\n",
      "Epoch 12/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7225\n",
      "Adv Train Loss: 1.7225\n",
      "Validation Clean Accuracy: 57.71%\n",
      "Validation Adversarial Accuracy: 68.73%\n",
      "Epoch 13/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.6831\n",
      "Adv Train Loss: 1.6831\n",
      "Validation Clean Accuracy: 57.62%\n",
      "Validation Adversarial Accuracy: 67.93%\n",
      "Epoch 14/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7181\n",
      "Adv Train Loss: 1.7181\n",
      "Validation Clean Accuracy: 57.69%\n",
      "Validation Adversarial Accuracy: 65.10%\n",
      "Epoch 15/15 - Adversarial fine-tuning\n",
      "Adversarial training epoch loss: 1.7392\n",
      "Adv Train Loss: 1.7392\n",
      "Validation Clean Accuracy: 57.73%\n",
      "Validation Adversarial Accuracy: 65.32%\n"
     ]
    }
   ],
   "source": [
    "best_adv_val_acc = 0.0\n",
    "best_adv_model_path = \"best_adv_model4.pt\"\n",
    "num_adv_epochs = 15\n",
    "\n",
    "for epoch in range(num_adv_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_adv_epochs} - Adversarial fine-tuning\")\n",
    "    adv_loss = train_one_epoch_adv(model, train_loader, optimizer, criterion, device,\n",
    "                                  eps=4/255, alpha=1/255, pgd_iters=7, mix_clean=True)\n",
    "    print(f\"Adv Train Loss: {adv_loss:.4f}\")\n",
    "    \n",
    "    val_acc, adv_acc = validate(model, val_loader, device, attack=pgd_attack,\n",
    "                               eps=4/255, alpha=1/255, iters=7)\n",
    "    print(f\"Validation Clean Accuracy: {val_acc:.2f}%\")\n",
    "    print(f\"Validation Adversarial Accuracy: {adv_acc:.2f}%\")\n",
    "    \n",
    "    # Save checkpoint if adversarial accuracy improved\n",
    "    if adv_acc > best_adv_val_acc:\n",
    "        best_adv_val_acc = adv_acc\n",
    "        torch.save(model.state_dict(), best_adv_model_path)\n",
    "        print(f\"Saved best adversarial fine-tuned model at epoch {epoch+1} with adv accuracy {adv_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea660d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final model for submission...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save final model for submission\n",
    "print(\"Saving final model for submission...\")\n",
    "torch.save(model.state_dict(), \"final_submission_model4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30555b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clean_accuracy': 0.6093333333333333, 'fgsm_accuracy': 0.123, 'pgd_accuracy': 0.005}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "token = \"53077688\"  # your token here\n",
    "\n",
    "with open(\"submission_model.pt\", \"rb\") as f:\n",
    "    response = requests.post(\n",
    "        \"http://34.122.51.94:9090/robustness\",\n",
    "        files={\"file\": f},\n",
    "        headers={\"token\": token, \"model-name\": \"resnet18\"}\n",
    "    )\n",
    "\n",
    "\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3bb4c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detail': \"Error during evaluation, e=HTTPException(status_code=400, detail='Model clean accuracy is too low.')\"}\n"
     ]
    }
   ],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652b88e",
   "metadata": {},
   "source": [
    "c:\\Users\\maitr\\miniconda3\\envs\\tf\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
    "  warnings.warn(\n",
    "{'clean_accuracy': 0.563, 'fgsm_accuracy': 0.301, 'pgd_accuracy': 0.26266666666666666}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
