{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34163f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import __main__\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#GPU \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "class ImgLabelDataset(Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base = base_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.base[idx]\n",
    "        return sample[1], sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5)\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset of length: 100000\n"
     ]
    }
   ],
   "source": [
    "torch.serialization.add_safe_globals([__main__.TaskDataset])\n",
    "\n",
    "dataset = torch.load(\"Train.pt\", weights_only=False)\n",
    "print(f\"Loaded dataset of length: {len(dataset)}\")\n",
    "\n",
    "# Split Datsaet into Train and Validation 90/10\n",
    "dataset_size = len(dataset)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe01941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(ImgLabelDataset(train_dataset), batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(ImgLabelDataset(val_dataset), batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b96f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model - Resnet18\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4cb8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD (Projected Gradient Descent) attack implementation.\n",
    "# Perturbs images within L-infinity ball of size eps.\n",
    "\n",
    "def pgd_attack(model, images, labels, eps, alpha, iters, device='cuda'):\n",
    "    model.eval()\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    ori_images = images.clone().detach()\n",
    "    perturbed_images = images + torch.empty_like(images).uniform_(-eps, eps)\n",
    "    perturbed_images = torch.clamp(perturbed_images, 0, 1).detach()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for _ in range(iters):\n",
    "        perturbed_images.requires_grad = True\n",
    "        outputs = model(perturbed_images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad_sign = perturbed_images.grad.sign()\n",
    "        adv_images = perturbed_images + alpha * grad_sign\n",
    "        eta = torch.clamp(adv_images - ori_images, -eps, eps)\n",
    "        perturbed_images = torch.clamp(ori_images + eta, 0, 1).detach()\n",
    "    model.train()\n",
    "    return perturbed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for one epoch on clean (unperturbed) data.\n",
    "\n",
    "def train_one_epoch_clean(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8928b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for one epoch using adversarial training.\n",
    "# mix_clean=True: loss is averaged between clean and adversarial examples.\n",
    "\n",
    "def train_one_epoch_adv(model, loader, optimizer, criterion, device,\n",
    "                        eps=4/255, alpha=1/255, pgd_iters=7, mix_clean=True):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        adv_imgs = pgd_attack(model, imgs, labels, eps, alpha, pgd_iters, device)\n",
    "        optimizer.zero_grad()\n",
    "        if mix_clean:\n",
    "            out_clean = model(imgs)\n",
    "            out_adv = model(adv_imgs)\n",
    "            loss = 0.5 * (criterion(out_clean, labels) + criterion(out_adv, labels))\n",
    "        else:\n",
    "            out_adv = model(adv_imgs)\n",
    "            loss = criterion(out_adv, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model. Returns accuracy on clean data, and on adversarial data if an attack function is provided.\n",
    "\n",
    "def validate(model, loader, device, attack=None, eps=4/255, alpha=1/255, iters=7):\n",
    "    model.eval()\n",
    "    correct_clean = 0\n",
    "    correct_adv = 0\n",
    "    total = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        total += labels.size(0)\n",
    "        outputs = model(imgs)\n",
    "        _, pred = outputs.max(1)\n",
    "        correct_clean += pred.eq(labels).sum().item()\n",
    "        if attack is not None:\n",
    "            with torch.enable_grad():\n",
    "                adv_imgs = attack(model, imgs, labels, eps, alpha, iters, device=device)\n",
    "            outputs_adv = model(adv_imgs)\n",
    "            _, pred_adv = outputs_adv.max(1)\n",
    "            correct_adv += pred_adv.eq(labels).sum().item()\n",
    "    clean_acc = 100 * correct_clean / total\n",
    "    adv_acc = 100 * correct_adv / total if attack is not None else None\n",
    "    return clean_acc, adv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b488e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- TRAINING FLOW ----\n",
    "best_val_acc = 0\n",
    "best_model_path = \"submission_model01.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6db03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 - Clean training\n",
      "Loss: 1.3313\n",
      "Validation Accuracy: 41.38%\n",
      "Saved best clean model with accuracy 41.38%\n",
      "Epoch 2/40 - Clean training\n",
      "Loss: 1.1916\n",
      "Validation Accuracy: 53.26%\n",
      "Saved best clean model with accuracy 53.26%\n",
      "Epoch 3/40 - Clean training\n",
      "Loss: 1.1234\n",
      "Validation Accuracy: 58.63%\n",
      "Saved best clean model with accuracy 58.63%\n",
      "Epoch 4/40 - Clean training\n",
      "Loss: 1.0705\n",
      "Validation Accuracy: 59.99%\n",
      "Saved best clean model with accuracy 59.99%\n",
      "Epoch 5/40 - Clean training\n",
      "Loss: 1.0249\n",
      "Validation Accuracy: 59.83%\n",
      "Epoch 6/40 - Clean training\n",
      "Loss: 0.9804\n",
      "Validation Accuracy: 62.18%\n",
      "Saved best clean model with accuracy 62.18%\n",
      "Epoch 7/40 - Clean training\n",
      "Loss: 0.9359\n",
      "Validation Accuracy: 61.23%\n",
      "Epoch 8/40 - Clean training\n",
      "Loss: 0.8830\n",
      "Validation Accuracy: 55.64%\n",
      "Epoch 9/40 - Clean training\n",
      "Loss: 0.8226\n",
      "Validation Accuracy: 58.13%\n",
      "Epoch 10/40 - Clean training\n",
      "Loss: 0.7538\n",
      "Validation Accuracy: 60.90%\n",
      "Epoch 11/40 - Clean training\n",
      "Loss: 0.6809\n",
      "Validation Accuracy: 60.45%\n",
      "Epoch 12/40 - Clean training\n",
      "Loss: 0.5931\n",
      "Validation Accuracy: 59.44%\n",
      "Epoch 13/40 - Clean training\n",
      "Loss: 0.5046\n",
      "Validation Accuracy: 58.37%\n",
      "Epoch 14/40 - Clean training\n",
      "Loss: 0.4223\n",
      "Validation Accuracy: 58.00%\n",
      "Epoch 15/40 - Clean training\n",
      "Loss: 0.3649\n",
      "Validation Accuracy: 57.17%\n",
      "Epoch 16/40 - Clean training\n",
      "Loss: 0.3092\n",
      "Validation Accuracy: 57.55%\n",
      "Epoch 17/40 - Clean training\n",
      "Loss: 0.2652\n",
      "Validation Accuracy: 58.56%\n",
      "Epoch 18/40 - Clean training\n",
      "Loss: 0.2236\n",
      "Validation Accuracy: 58.16%\n",
      "Epoch 19/40 - Clean training\n",
      "Loss: 0.2097\n",
      "Validation Accuracy: 57.29%\n",
      "Epoch 20/40 - Clean training\n",
      "Loss: 0.1822\n",
      "Validation Accuracy: 56.35%\n",
      "Epoch 21/40 - Clean training\n",
      "Loss: 0.1616\n",
      "Validation Accuracy: 55.42%\n",
      "Epoch 22/40 - Clean training\n",
      "Loss: 0.1499\n",
      "Validation Accuracy: 58.28%\n",
      "Epoch 23/40 - Clean training\n",
      "Loss: 0.1435\n",
      "Validation Accuracy: 58.27%\n",
      "Epoch 24/40 - Clean training\n",
      "Loss: 0.1309\n",
      "Validation Accuracy: 57.52%\n",
      "Epoch 25/40 - Clean training\n",
      "Loss: 0.1153\n",
      "Validation Accuracy: 57.67%\n",
      "Epoch 26/40 - Clean training\n",
      "Loss: 0.1309\n",
      "Validation Accuracy: 57.05%\n",
      "Epoch 27/40 - Clean training\n",
      "Loss: 0.1033\n",
      "Validation Accuracy: 57.73%\n",
      "Epoch 28/40 - Clean training\n",
      "Loss: 0.1085\n",
      "Validation Accuracy: 56.81%\n",
      "Epoch 29/40 - Clean training\n",
      "Loss: 0.1005\n",
      "Validation Accuracy: 58.00%\n",
      "Epoch 30/40 - Clean training\n",
      "Loss: 0.0950\n",
      "Validation Accuracy: 58.37%\n",
      "Epoch 31/40 - Clean training\n",
      "Loss: 0.0873\n",
      "Validation Accuracy: 58.42%\n",
      "Epoch 32/40 - Clean training\n",
      "Loss: 0.0867\n",
      "Validation Accuracy: 57.59%\n",
      "Epoch 33/40 - Clean training\n",
      "Loss: 0.0782\n",
      "Validation Accuracy: 58.89%\n",
      "Epoch 34/40 - Clean training\n",
      "Loss: 0.0778\n",
      "Validation Accuracy: 57.43%\n",
      "Epoch 35/40 - Clean training\n",
      "Loss: 0.0829\n",
      "Validation Accuracy: 58.36%\n",
      "Epoch 36/40 - Clean training\n",
      "Loss: 0.0846\n",
      "Validation Accuracy: 57.30%\n",
      "Epoch 37/40 - Clean training\n",
      "Loss: 0.0695\n",
      "Validation Accuracy: 58.16%\n",
      "Epoch 38/40 - Clean training\n",
      "Loss: 0.0749\n",
      "Validation Accuracy: 55.88%\n",
      "Epoch 39/40 - Clean training\n",
      "Loss: 0.0833\n",
      "Validation Accuracy: 58.13%\n",
      "Epoch 40/40 - Clean training\n",
      "Loss: 0.0609\n",
      "Validation Accuracy: 57.87%\n"
     ]
    }
   ],
   "source": [
    "# Clean Training\n",
    "for epoch in range(40):\n",
    "    print(f\"Epoch {epoch+1}/40 - Clean training\")\n",
    "    loss = train_one_epoch_clean(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Loss: {loss:.4f}\")\n",
    "    val_acc, _ = validate(model, val_loader, device)\n",
    "    print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best clean model with accuracy {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ba668",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.6508\n",
      "Validation Clean Accuracy: 53.39%\n",
      "Validation Adversarial Accuracy: 33.65%\n",
      "Saved best adversarial fine-tuned model at epoch 1 with adv accuracy 33.65%\n",
      "Epoch 2/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.4718\n",
      "Validation Clean Accuracy: 54.06%\n",
      "Validation Adversarial Accuracy: 36.53%\n",
      "Saved best adversarial fine-tuned model at epoch 2 with adv accuracy 36.53%\n",
      "Epoch 3/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.4393\n",
      "Validation Clean Accuracy: 54.55%\n",
      "Validation Adversarial Accuracy: 37.31%\n",
      "Saved best adversarial fine-tuned model at epoch 3 with adv accuracy 37.31%\n",
      "Epoch 4/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.4197\n",
      "Validation Clean Accuracy: 54.82%\n",
      "Validation Adversarial Accuracy: 38.04%\n",
      "Saved best adversarial fine-tuned model at epoch 4 with adv accuracy 38.04%\n",
      "Epoch 5/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.4038\n",
      "Validation Clean Accuracy: 54.57%\n",
      "Validation Adversarial Accuracy: 38.76%\n",
      "Saved best adversarial fine-tuned model at epoch 5 with adv accuracy 38.76%\n",
      "Epoch 6/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.3893\n",
      "Validation Clean Accuracy: 55.43%\n",
      "Validation Adversarial Accuracy: 38.78%\n",
      "Saved best adversarial fine-tuned model at epoch 6 with adv accuracy 38.78%\n",
      "Epoch 7/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.3717\n",
      "Validation Clean Accuracy: 56.41%\n",
      "Validation Adversarial Accuracy: 39.81%\n",
      "Saved best adversarial fine-tuned model at epoch 7 with adv accuracy 39.81%\n",
      "Epoch 8/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.3441\n",
      "Validation Clean Accuracy: 57.62%\n",
      "Validation Adversarial Accuracy: 40.49%\n",
      "Saved best adversarial fine-tuned model at epoch 8 with adv accuracy 40.49%\n",
      "Epoch 9/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.3055\n",
      "Validation Clean Accuracy: 58.84%\n",
      "Validation Adversarial Accuracy: 43.32%\n",
      "Saved best adversarial fine-tuned model at epoch 9 with adv accuracy 43.32%\n",
      "Epoch 10/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.2720\n",
      "Validation Clean Accuracy: 59.22%\n",
      "Validation Adversarial Accuracy: 42.87%\n",
      "Epoch 11/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.2340\n",
      "Validation Clean Accuracy: 59.84%\n",
      "Validation Adversarial Accuracy: 48.96%\n",
      "Saved best adversarial fine-tuned model at epoch 11 with adv accuracy 48.96%\n",
      "Epoch 12/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.1978\n",
      "Validation Clean Accuracy: 59.96%\n",
      "Validation Adversarial Accuracy: 34.03%\n",
      "Epoch 13/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.1754\n",
      "Validation Clean Accuracy: 60.66%\n",
      "Validation Adversarial Accuracy: 44.54%\n",
      "Epoch 14/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.1391\n",
      "Validation Clean Accuracy: 60.25%\n",
      "Validation Adversarial Accuracy: 59.95%\n",
      "Saved best adversarial fine-tuned model at epoch 14 with adv accuracy 59.95%\n",
      "Epoch 15/15 - Adversarial fine-tuning\n",
      "Adv Train Loss: 1.1241\n",
      "Validation Clean Accuracy: 59.92%\n",
      "Validation Adversarial Accuracy: 58.29%\n"
     ]
    }
   ],
   "source": [
    "# Adversarial Fine-Tuning\n",
    "\n",
    "best_adv_val_acc = 0.0\n",
    "best_adv_model_path = \"best_adv_model01.pt\"\n",
    "num_adv_epochs = 15\n",
    "\n",
    "for epoch in range(num_adv_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_adv_epochs} - Adversarial fine-tuning\")\n",
    "    adv_loss = train_one_epoch_adv(model, train_loader, optimizer, criterion, device,\n",
    "                                  eps=4/255, alpha=1/255, pgd_iters=7, mix_clean=True)\n",
    "    print(f\"Adv Train Loss: {adv_loss:.4f}\")\n",
    "    \n",
    "    val_acc, adv_acc = validate(model, val_loader, device, attack=pgd_attack,\n",
    "                               eps=4/255, alpha=1/255, iters=7)\n",
    "    print(f\"Validation Clean Accuracy: {val_acc:.2f}%\")\n",
    "    print(f\"Validation Adversarial Accuracy: {adv_acc:.2f}%\")\n",
    "    \n",
    "    # Save checkpoint if adversarial accuracy improved\n",
    "    if adv_acc > best_adv_val_acc:\n",
    "        best_adv_val_acc = adv_acc\n",
    "        torch.save(model.state_dict(), best_adv_model_path)\n",
    "        print(f\"Saved best adversarial fine-tuned model at epoch {epoch+1} with adv accuracy {adv_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea660d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final model for submission...\n"
     ]
    }
   ],
   "source": [
    "# Save final model for submission\n",
    "\n",
    "print(\"Saving final model for submission...\")\n",
    "torch.save(model.state_dict(), \"final_submission_model01.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30555b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maitr\\miniconda3\\envs\\tf\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clean_accuracy': 0.5746666666666667, 'fgsm_accuracy': 0.29633333333333334, 'pgd_accuracy': 0.10433333333333333}\n"
     ]
    }
   ],
   "source": [
    "# Submission\n",
    "\n",
    "token = \"53077688\"  # your token here\n",
    "\n",
    "with open(\"final_submission_model01.pt\", \"rb\") as f:\n",
    "    response = requests.post(\n",
    "        \"http://34.122.51.94:9090/robustness\",\n",
    "        files={\"file\": f},\n",
    "        headers={\"token\": token, \"model-name\": \"resnet18\"}\n",
    "    )\n",
    "\n",
    "\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
